@misc{li2024fedcaprobustfederatedlearning,
abbr={ACSAC 2024},
bibtex_show={true},
selected={true},
title={FedCAP: Robust Federated Learning via Customized Aggregation and Personalization}, 
author={Youpeng Li and Xinda Wang and Fuxun Yu and Lichao Sun and Wenbin Zhang and Xuyu Wang},
year={2024},
month={oct},
eprint={2410.13083},
archivePrefix={arXiv},
primaryClass={cs.LG},
booktitle={Annual Computer Security Applications Conference},
url={https://arxiv.org/abs/2410.13083}, 
pdf = {https://arxiv.org/abs/2410.13083},
code = {https://github.com/youpengl/FedCAP},
abstract = {Federated learning (FL), an emerging distributed machine learning paradigm, has been applied to various privacy-preserving scenarios. However, due to its distributed nature, FL faces two key issues: the non-independent and identical distribution (non-IID) of user data and vulnerability to Byzantine threats. To address these challenges, in this paper, we propose FedCAP, a robust FL framework against both data heterogeneity and Byzantine attacks. The core of FedCAP is a model update calibration mechanism to help a server capture the differences in the direction and magnitude of model updates among clients. Furthermore, we design a customized model aggregation rule that facilitates collaborative training among similar clients while accelerating the model deterioration of malicious clients. With a Euclidean norm-based anomaly detection mechanism, the server can quickly identify and permanently remove malicious clients. Moreover, the impact of data heterogeneity and Byzantine attacks can be further mitigated through personalization on the client side. We conduct extensive experiments, comparing multiple state-of-the-art baselines, to demonstrate that FedCAP performs well in several non-IID settings and shows strong robustness under a series of poisoning attacks.},
keywords = {federated learning, data heterogeneity, Byzantine-robustness},
doi = {https://doi.org/10.48550/arXiv.2410.13083}
}

@article{10.1145/3580795,
abbr={IMWUT 2023},
bibtex_show={true},
selected={true},
author = {Li, Youpeng and Wang, Xuyu and An, Lingling},
title = {Hierarchical Clustering-Based Personalized Federated Learning for Robust and Fair Human Activity Recognition},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
pdf = {https://dl.acm.org/doi/pdf/10.1145/3580795},
code = {https://github.com/youpengl/FedCHAR},
doi = {10.1145/3580795},
abstract = {Currently, federated learning (FL) can enable users to collaboratively train a global model while protecting the privacy of user data, which has been applied to human activity recognition (HAR) tasks. However, in real HAR scenarios, deploying an FL system needs to consider multiple aspects, including system accuracy, fairness, robustness, and scalability. Most existing FL frameworks aim to solve specific problems while ignoring other properties. In this paper, we propose FedCHAR, a personalized FL framework with a hierarchical clustering method for robust and fair HAR, which not only improves the accuracy and the fairness of model performance by exploiting the intrinsically similar relationship between users but also enhances the robustness of the system by identifying malicious nodes through clustering in attack scenarios. In addition, to enhance the scalability of FedCHAR, we also propose FedCHAR-DC, a scalable and adaptive FL framework which is featured by dynamic clustering and adapting to the addition of new users or the evolution of datasets for realistic FL-based HAR scenarios. We conduct extensive experiments to evaluate the performance of FedCHAR on seven datasets of different sizes. The results demonstrate that FedCHAR could obtain better performance on different datasets than the other five state-of-the-art methods in terms of accuracy, robustness, and fairness. We further validate that FedCHAR-DC exhibits satisfactory scalability on three large-scale datasets regardless of the number of participants.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {mar},
articleno = {20},
numpages = {38},
keywords = {fairness, attack and defense, human activity recognition, federated learning}
}

@article{10.1145/3678571,
abbr={IMWUT 2024},
bibtex_show={true},
selected={true},
author = {Zhang, Weibin and Li, Youpeng and An, Lingling and Wan, Bo and Wang, Xuyu},
title = {SARS: A Personalized Federated Learning Framework Towards Fairness and Robustness against Backdoor Attacks},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3678571},
doi = {10.1145/3678571},
abstract = {Federated Learning (FL), an emerging distributed machine learning framework that enables each client to collaboratively train a global model by sharing local knowledge without disclosing local private data, is vulnerable to backdoor model poisoning attacks. By compromising some users, the attacker manipulates their local training process, and uploads malicious gradient updates to poison the global model, resulting in the poisoned global model behaving abnormally on the sub-tasks specified by the malicious user. Prior research has proposed various strategies to mitigate backdoor attacks. However, existing FL backdoor defense methods affect the fairness of the FL system, while fair FL performance may not be robust. Motivated by these concerns, in this paper, we propose Self-Awareness Revision (SARS), a personalized FL framework designed to resist backdoor attacks and ensure the fairness of the FL system. SARS consists of two key modules: adaptation feature extraction and knowledge mapping. In the adaptation feature extraction module, benign users can adaptively extract clean global knowledge with self-awareness and self-revision of the backdoor knowledge transferred from the global model. Based on the previous module, users can effectively ensure the correct mapping of clean sample features and labels. Through extensive experimental results, SARS can defend against backdoor attacks and improve the fairness of the FL system by comparing several state-of-the-art FL backdoor defenses or fair FL methods, including FedAvg, Ditto, WeakDP, FoolsGold, and FLAME.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {nov},
articleno = {140},
numpages = {24},
keywords = {Attention Distillation, Backdoor Attack, Fairness, Federated Learning}
}