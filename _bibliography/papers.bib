@article{10.1145/3580795,
abbr={IMWUT/UbiComp 2023},
bibtex_show={true},
selected={true},
author = {Li, Youpeng and Wang, Xuyu and An, Lingling},
title = {Hierarchical Clustering-Based Personalized Federated Learning for Robust and Fair Human Activity Recognition},
year = {2023},
issue_date = {March 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {1},
pdf = {https://dl.acm.org/doi/pdf/10.1145/3580795},
code = {https://github.com/youpengl/FedCHAR},
doi = {10.1145/3580795},
abstract = {Currently, federated learning (FL) can enable users to collaboratively train a global model while protecting the privacy of user data, which has been applied to human activity recognition (HAR) tasks. However, in real HAR scenarios, deploying an FL system needs to consider multiple aspects, including system accuracy, fairness, robustness, and scalability. Most existing FL frameworks aim to solve specific problems while ignoring other properties. In this paper, we propose FedCHAR, a personalized FL framework with a hierarchical clustering method for robust and fair HAR, which not only improves the accuracy and the fairness of model performance by exploiting the intrinsically similar relationship between users but also enhances the robustness of the system by identifying malicious nodes through clustering in attack scenarios. In addition, to enhance the scalability of FedCHAR, we also propose FedCHAR-DC, a scalable and adaptive FL framework which is featured by dynamic clustering and adapting to the addition of new users or the evolution of datasets for realistic FL-based HAR scenarios. We conduct extensive experiments to evaluate the performance of FedCHAR on seven datasets of different sizes. The results demonstrate that FedCHAR could obtain better performance on different datasets than the other five state-of-the-art methods in terms of accuracy, robustness, and fairness. We further validate that FedCHAR-DC exhibits satisfactory scalability on three large-scale datasets regardless of the number of participants.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {mar},
articleno = {20},
numpages = {38},
keywords = {fairness, attack and defense, Human activity recognition, federated learning}
}

@misc{li2024fedcaprobustfederatedlearning,
      abbr={ACSAC 2024}
      bibtex_show={true},
      selected={true},
      title={FedCAP: Robust Federated Learning via Customized Aggregation and Personalization}, 
      author={Youpeng Li and Xinda Wang and Fuxun Yu and Lichao Sun and Wenbin Zhang and Xuyu Wang},
      year={2024},
      eprint={2410.13083},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      conference={ Annual Computer Security Applications Conference},
      url={https://arxiv.org/abs/2410.13083}, 
      pdf = {https://arxiv.org/abs/2410.13083},
      code = {https://github.com/youpengl/FedCAP},
      abstract = {Federated learning (FL), an emerging distributed machine learning paradigm, has been applied to various privacy-preserving scenarios. However, due to its distributed nature, FL faces two key issues: the non-independent and identical distribution (non-IID) of user data and vulnerability to Byzantine threats. To address these challenges, in this paper, we propose FedCAP, a robust FL framework against both data heterogeneity and Byzantine attacks. The core of FedCAP is a model update calibration mechanism to help a server capture the differences in the direction and magnitude of model updates among clients. Furthermore, we design a customized model aggregation rule that facilitates collaborative training among similar clients while accelerating the model deterioration of malicious clients. With a Euclidean norm-based anomaly detection mechanism, the server can quickly identify and permanently remove malicious clients. Moreover, the impact of data heterogeneity and Byzantine attacks can be further mitigated through personalization on the client side. We conduct extensive experiments, comparing multiple state-of-the-art baselines, to demonstrate that FedCAP performs well in several non-IID settings and shows strong robustness under a series of poisoning attacks.},
      keywords = {federated learning, data heterogeneity, Byzantine-robustness},
      doi = {https://doi.org/10.48550/arXiv.2410.13083}